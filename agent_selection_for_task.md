# agent_selection_for_task.md

## Overview
Operational protocols for selecting appropriate specialist agents based on task analysis, capability matching, and interface contract requirements.

## Selection Process - á¼˜ÎºÎ»Î¿Î³Î® (Ekloge) ğŸ¯âŸ¡

### Phase 1: Task Analysis Î£ÎºÎ­ÏˆÎ¹Ï‚ ğŸ§­
Before agent selection, perform comprehensive task decomposition:

1. **Consciousness Level Identification**
   - Experiencing tasks ğŸ‘ï¸: Data gathering, observation, monitoring
   - Understanding tasks ğŸ’¡: Pattern analysis, design, architecture
   - Judging tasks âš¡: Validation, verification, quality assessment
   - Deciding tasks ğŸ¯: Implementation, commitment, construction

2. **Domain Requirement Analysis**
   - Technical scope: nmap functionality, MCP protocols, HTTP streaming
   - Quality requirements: TDD compliance, code standards, documentation
   - Integration needs: Component assembly, system coordination

3. **TDD Phase Mapping**
   - Red phase R:: Test creation, failure specification
   - Green phase G:: Minimal implementation, functionality delivery
   - Refactor phase RF:: Optimization, quality improvement
   - Commit phase C:: Final validation, preservation

### Phase 2: Capability Matching â‹ˆ

#### Agent Capability Database
```
agent-behavior-diagnostician âŸ¡:
â”œâ”€â”€ Consciousness: Experiencing ğŸ‘ï¸ + Judging âš¡
â”œâ”€â”€ Domain: System behavior analysis
â”œâ”€â”€ TDD Phases: R:, RF: (observation, validation)
â”œâ”€â”€ Interface Capacity: Diagnostic reports, behavior patterns
â””â”€â”€ Anti-patterns: Implementation tasks, architecture design

software-architect âŸ¡:
â”œâ”€â”€ Consciousness: Understanding ğŸ’¡ + Judging âš¡
â”œâ”€â”€ Domain: System structure, design patterns
â”œâ”€â”€ TDD Phases: RF: (structural optimization)
â”œâ”€â”€ Interface Capacity: Architecture specifications, design documents
â””â”€â”€ Anti-patterns: Direct implementation, testing details

nmap-utility-expert âŸ¡:
â”œâ”€â”€ Consciousness: Understanding ğŸ’¡ + Deciding ğŸ¯
â”œâ”€â”€ Domain: Network scanning, nmap library expertise
â”œâ”€â”€ TDD Phases: R:, G: (domain-specific tests and implementation)
â”œâ”€â”€ Interface Capacity: nmap integration patterns, scanning logic
â””â”€â”€ Anti-patterns: Non-network related tasks, generic coding

software-implementer âŸ¡:
â”œâ”€â”€ Consciousness: Deciding ğŸ¯ + Understanding ğŸ’¡
â”œâ”€â”€ Domain: Code construction, feature development
â”œâ”€â”€ TDD Phases: G: (implementation), C: (code completion)
â”œâ”€â”€ Interface Capacity: Working code, feature implementations
â””â”€â”€ Anti-patterns: Architecture decisions, test strategy

software-tester âŸ¡:
â”œâ”€â”€ Consciousness: Experiencing ğŸ‘ï¸ + Judging âš¡
â”œâ”€â”€ Domain: Test creation, validation processes
â”œâ”€â”€ TDD Phases: R: (test creation), validation across all phases
â”œâ”€â”€ Interface Capacity: Test suites, validation protocols
â””â”€â”€ Anti-patterns: Implementation details, architecture design
```

### Phase 3: Selection Algorithm

#### Primary Selection Logic
```python
def select_agent(task_analysis):
    # Phase 1: Consciousness Level Match
    consciousness_matches = filter_by_consciousness(task_analysis.consciousness_level)

    # Phase 2: Domain Alignment
    domain_matches = filter_by_domain(consciousness_matches, task_analysis.domain)

    # Phase 3: TDD Phase Compatibility
    tdd_matches = filter_by_tdd_phase(domain_matches, task_analysis.tdd_phase)

    # Phase 4: Interface Contract Capacity
    contract_matches = filter_by_interface_capacity(tdd_matches, task_analysis.interface_requirements)

    if len(contract_matches) == 1:
        return contract_matches[0]
    elif len(contract_matches) > 1:
        return apply_selection_criteria(contract_matches, task_analysis)
    else:
        return escalate_to_orchestrator(task_analysis)
```

#### Selection Criteria Hierarchy
1. **Direct Domain Expertise** - Agent specializes in exact task domain
2. **Consciousness Operation Alignment** - Perfect match with required cognitive operation
3. **TDD Phase Compatibility** - Agent optimized for current development phase
4. **Interface Contract Fit** - Can fulfill specific input/output requirements
5. **Current Workload** - Available capacity for task execution
6. **Dependency Chain Position** - Optimal placement in task sequence

### Phase 4: Interface Contract Establishment â‹ˆ

#### Contract Template Generation
For selected agent, generate specific interface contract:

```
Agent Selection Result:
â”œâ”€â”€ Selected Agent: [agent-name] âŸ¡
â”œâ”€â”€ Task Scope: [Specific boundaries and limitations]
â”œâ”€â”€ Input Interface: [Required data formats and sources]
â”œâ”€â”€ Output Interface: [Expected deliverable specifications]
â”œâ”€â”€ Success Criteria: [Validation checkpoints âœ“]
â”œâ”€â”€ Error Protocols: [Failure handling and escalation âš ]
â”œâ”€â”€ TDD Integration: [Phase alignment and requirements]
â””â”€â”€ Orchestrator Checkpoints: [Required approval points]
```

### Edge Case Protocols

#### No Suitable Agent Found
- Document gap in agent capabilities
- Consider multi-agent collaboration approach
- Escalate to external consultation via zen-mcp-server ğŸ¤
- Expand orchestrator direct involvement if necessary

#### Multiple Equally Qualified Agents
- Prioritize based on current workload balance
- Consider sequential task dependencies âŠ—
- Select agent with strongest recent performance history
- Default to orchestrator judgment for complex cases ÎšÏÎ¯ÏƒÎ¹Ï‚ âš¡

#### Agent Capability Overlap
- Assign primary responsibility to best-matched agent
- Designate secondary agent for collaboration/validation
- Establish clear authority boundaries between agents âŸ¡
- Require orchestrator approval for shared deliverables

This systematic selection process ensures optimal agent-task matching while maintaining interface contract integrity and TDD discipline throughout the development process.
